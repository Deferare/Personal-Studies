{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_Model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM2Wc0rNoQ28gFCiu45gvZm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OurKawQesbbf","executionInfo":{"status":"ok","timestamp":1621470609381,"user_tz":-540,"elapsed":3465,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"8d3aab7c-cfbd-42b5-e649-f290011439cc"},"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","# GPU를 사용 가능하면 할당.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using {} device\".format(device))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using cuda device\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltiIUb1-tWcm","executionInfo":{"status":"ok","timestamp":1621470953790,"user_tz":-540,"elapsed":772,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}}},"source":["#모델 구현 클래스\n","\n","class NeuralNetwork(nn.Module):\n","\n","    def __init__(self):  # 모델을 인스턴스화할때, 딱 한번 실행이 되는데 레이어 층을 구현하는 함수다.\n","        print(\"init Callback!\")\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","        )\n","    def forward(self, x):\n","        print(\"origin x : \",x.shape)\n","        x = self.flatten(x) # 데이터를 학습 할 수 있게, 1차원으로 reshape 한다.\n","        print(\"x : \", x.shape)\n","        logits = self.linear_relu_stack(x) # 위의 init에 구현된 linear_relu_stack을 활용.\n","        return logits"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9tRiUgPuW5b","executionInfo":{"status":"ok","timestamp":1621470953790,"user_tz":-540,"elapsed":639,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"89212429-bd55-47db-dc36-1acff5f6fe85"},"source":["# 인스턴스 생성\n","model = NeuralNetwork().to(device)\n","print(model)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["init Callback!\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","    (5): ReLU()\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OArPCKgdvE0U","executionInfo":{"status":"ok","timestamp":1621472205789,"user_tz":-540,"elapsed":682,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"87e8a5f7-0a48-47fd-a459-79e81025ef1c"},"source":["# 임시 데이터 생성\n","X = torch.rand(1,28, 28, device=device)\n","\n","# 만든 모델에 입력\n","logits = model(X)\n","print(logits)\n","\n","# 마지막에 다중분류에 특화된 softmax 맥임.\n","pred_probab = nn.Softmax(dim=1)(logits)\n","print(pred_probab)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class : {y_pred}\")"],"execution_count":37,"outputs":[{"output_type":"stream","text":["origin x :  torch.Size([1, 28, 28])\n","x :  torch.Size([1, 784])\n","tensor([[0.0000, 0.0000, 0.0000, 0.0554, 0.0000, 0.1010, 0.0000, 0.0000, 0.0000,\n","         0.0401]], device='cuda:0', grad_fn=<ReluBackward0>)\n","tensor([[0.0980, 0.0980, 0.0980, 0.1036, 0.0980, 0.1084, 0.0980, 0.0980, 0.0980,\n","         0.1020]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n","Predicted class : tensor([5], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z39b8penzB3c"},"source":["# 모델 계층(Layer)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fO_4ObNFwkbL","executionInfo":{"status":"ok","timestamp":1621471132699,"user_tz":-540,"elapsed":576,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"d728086a-8ae4-4922-fd37-7fbcad133e45"},"source":["# 임시 모델 생성\n","input_image = torch.rand(3,28,28)\n","print(input_image.size())"],"execution_count":29,"outputs":[{"output_type":"stream","text":["torch.Size([3, 28, 28])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiPWH79zzAvO","executionInfo":{"status":"ok","timestamp":1621471154937,"user_tz":-540,"elapsed":643,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"d75279c3-80ec-4c11-c89f-fc744d4fa79d"},"source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image) # 학습할 수 있게 reshape\n","print(flat_image.size())"],"execution_count":30,"outputs":[{"output_type":"stream","text":["torch.Size([3, 784])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zu7hMm7XzZwo","executionInfo":{"status":"ok","timestamp":1621471226177,"user_tz":-540,"elapsed":597,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"13aec552-abf2-46a7-8d05-cc2d664c6c68"},"source":["layer1 = nn.Linear(in_features=28*28, out_features=20) # 레이어 층 만들고\n","hidden1 = layer1(flat_image) # 데이터 집어넣고 반환.\n","print(hidden1)\n","print(hidden1.shape)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["tensor([[ 0.2912,  0.5014,  0.0511, -0.1685, -0.4598, -0.1709, -0.1291,  0.2767,\n","          0.5760,  0.3112, -0.3815, -0.0134, -0.3582,  0.1622, -0.3334, -0.0987,\n","         -0.1561,  0.2987,  0.4022,  0.0617],\n","        [ 0.1432,  0.1082,  0.1536, -0.2488, -0.0448,  0.1661, -0.1316,  0.4279,\n","          0.3025,  0.0688, -0.4521, -0.2629,  0.3072,  0.1598,  0.1345, -0.2644,\n","         -0.6310,  0.4670,  0.2429,  0.4814],\n","        [ 0.1228,  0.0988,  0.3831, -0.0244, -0.3794, -0.1114,  0.0551,  0.1470,\n","          0.4379,  0.1929, -0.2155, -0.0739, -0.2644,  0.1255, -0.1824, -0.1541,\n","         -0.6471,  0.5988,  0.3571,  0.2197]], grad_fn=<AddmmBackward>)\n","torch.Size([3, 20])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFqdCfDLzevt","executionInfo":{"status":"ok","timestamp":1621471290491,"user_tz":-540,"elapsed":570,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"61c72446-272a-4863-d8a0-d3498e84adde"},"source":["print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1) # 활성화 함수에 집어넣고 반환\n","print(f\"After ReLU: {hidden1}\")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Before ReLU: tensor([[ 0.2912,  0.5014,  0.0511, -0.1685, -0.4598, -0.1709, -0.1291,  0.2767,\n","          0.5760,  0.3112, -0.3815, -0.0134, -0.3582,  0.1622, -0.3334, -0.0987,\n","         -0.1561,  0.2987,  0.4022,  0.0617],\n","        [ 0.1432,  0.1082,  0.1536, -0.2488, -0.0448,  0.1661, -0.1316,  0.4279,\n","          0.3025,  0.0688, -0.4521, -0.2629,  0.3072,  0.1598,  0.1345, -0.2644,\n","         -0.6310,  0.4670,  0.2429,  0.4814],\n","        [ 0.1228,  0.0988,  0.3831, -0.0244, -0.3794, -0.1114,  0.0551,  0.1470,\n","          0.4379,  0.1929, -0.2155, -0.0739, -0.2644,  0.1255, -0.1824, -0.1541,\n","         -0.6471,  0.5988,  0.3571,  0.2197]], grad_fn=<AddmmBackward>)\n","\n","\n","After ReLU: tensor([[0.2912, 0.5014, 0.0511, 0.0000, 0.0000, 0.0000, 0.0000, 0.2767, 0.5760,\n","         0.3112, 0.0000, 0.0000, 0.0000, 0.1622, 0.0000, 0.0000, 0.0000, 0.2987,\n","         0.4022, 0.0617],\n","        [0.1432, 0.1082, 0.1536, 0.0000, 0.0000, 0.1661, 0.0000, 0.4279, 0.3025,\n","         0.0688, 0.0000, 0.0000, 0.3072, 0.1598, 0.1345, 0.0000, 0.0000, 0.4670,\n","         0.2429, 0.4814],\n","        [0.1228, 0.0988, 0.3831, 0.0000, 0.0000, 0.0000, 0.0551, 0.1470, 0.4379,\n","         0.1929, 0.0000, 0.0000, 0.0000, 0.1255, 0.0000, 0.0000, 0.0000, 0.5988,\n","         0.3571, 0.2197]], grad_fn=<ReluBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZviHj-lo514O","executionInfo":{"status":"ok","timestamp":1621415716544,"user_tz":-540,"elapsed":716,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"cd2558d2-01d7-4ff3-dbb4-d56d5c346423"},"source":["seq_modules = nn.Sequential( # 위에 한걸 한번에 모아서 가능.\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)\n","print(logits)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[-0.1323,  0.1455,  0.0748, -0.2269, -0.0986,  0.0580, -0.0362,  0.3052,\n","          0.2291, -0.2180],\n","        [-0.1181,  0.2191,  0.1445, -0.1876, -0.0245,  0.0836, -0.0294,  0.2530,\n","          0.3107, -0.2355],\n","        [-0.1029,  0.1735, -0.0111, -0.1858, -0.1057,  0.0999, -0.0563,  0.2871,\n","          0.2004, -0.2145]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CouaivIX6CFw","executionInfo":{"status":"ok","timestamp":1621415778470,"user_tz":-540,"elapsed":643,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"67c50be3-3f45-4583-af1a-89268723d39f"},"source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)\n","print(pred_probab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0.0854, 0.1128, 0.1051, 0.0777, 0.0884, 0.1033, 0.0940, 0.1323, 0.1226,\n","         0.0784],\n","        [0.0839, 0.1175, 0.1091, 0.0782, 0.0921, 0.1026, 0.0917, 0.1216, 0.1288,\n","         0.0746],\n","        [0.0883, 0.1164, 0.0967, 0.0812, 0.0880, 0.1081, 0.0925, 0.1304, 0.1195,\n","         0.0789]], grad_fn=<SoftmaxBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSrW3GPv6UH7","executionInfo":{"status":"ok","timestamp":1621416207952,"user_tz":-540,"elapsed":602,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"23bc656c-9f2a-4f7b-8243-bfcb8bd55d1c"},"source":["print(\"Model structure: \", model, \"\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} \\n Values : {param[:2]} \\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model structure:  NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","    (5): ReLU()\n","  )\n",") \n","\n","\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) \n"," Values : tensor([[-0.0170, -0.0325,  0.0262,  ...,  0.0299,  0.0084,  0.0099],\n","        [-0.0294,  0.0196, -0.0114,  ...,  0.0324,  0.0055,  0.0225]],\n","       device='cuda:0', grad_fn=<SliceBackward>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) \n"," Values : tensor([ 0.0099, -0.0054], device='cuda:0', grad_fn=<SliceBackward>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) \n"," Values : tensor([[-0.0010,  0.0025,  0.0155,  ..., -0.0372, -0.0080,  0.0442],\n","        [ 0.0160, -0.0006, -0.0211,  ..., -0.0343,  0.0344,  0.0206]],\n","       device='cuda:0', grad_fn=<SliceBackward>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) \n"," Values : tensor([-0.0173,  0.0279], device='cuda:0', grad_fn=<SliceBackward>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) \n"," Values : tensor([[ 0.0425,  0.0089,  0.0033,  ...,  0.0111, -0.0353, -0.0120],\n","        [ 0.0051,  0.0143,  0.0250,  ..., -0.0242, -0.0291, -0.0390]],\n","       device='cuda:0', grad_fn=<SliceBackward>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) \n"," Values : tensor([ 0.0394, -0.0050], device='cuda:0', grad_fn=<SliceBackward>) \n","\n"],"name":"stdout"}]}]}