{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db36b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib, pymysql, calendar, time, json\n",
    "from urllib.request import urlopen, Request\n",
    "from datetime import datetime\n",
    "from threading import Timer\n",
    "from matplotlib import pyplot as plt\n",
    "from urllib import request as req\n",
    "class DBUpdater:  \n",
    "    def __init__(self):\n",
    "        \"\"\"생성자: MariaDB 연결 및 종목코드 딕셔너리 생성\"\"\"\n",
    "        self.conn = pymysql.connect(host='localhost', user='root',\n",
    "            password='1234', db='INVESTAR', charset='utf8')\n",
    "        with self.conn.cursor() as curs:\n",
    "            sql = \"\"\" \n",
    "            CREATE TABLE IF NOT EXISTS company_info ( \n",
    "                code VARCHAR(20),\n",
    "                company VARCHAR(40),\n",
    "                last_update DATE,\n",
    "                PRIMARY KEY (code))\n",
    "            \"\"\" # 이미 존재하는 테이블에 CREATE TABLE 구문을 사용하면 오류가 발생하기 때문에 경고 메세지만 표시하게 처리\n",
    "            curs.execute(sql)\n",
    "            sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS daily_price (\n",
    "                code VARCHAR(20),\n",
    "                date DATE,\n",
    "                open BIGINT(20),\n",
    "                high BIGINT(20),\n",
    "                low BIGINT(20),\n",
    "                close BIGINT(20),\n",
    "                diff BIGINT(20),\n",
    "                volume BIGINT(20),\n",
    "                PRIMARY KEY (code, date))\n",
    "            \"\"\"\n",
    "            curs.execute(sql)\n",
    "        self.conn.commit()\n",
    "        self.codes = dict()\n",
    "    def __del__(self):\n",
    "        \"\"\"소멸자: MariaDB 연결 해제\"\"\"\n",
    "        self.conn.close() \n",
    "    def read_krx_code(self):\n",
    "        \"\"\"KRX로부터 상장기업 목록 파일을 읽어와서 데이터프레임으로 반환\"\"\"\n",
    "        url = 'http://kind.krx.co.kr/corpgeneral/corpList.do?method='\\\n",
    "            'download&searchType=13'\n",
    "        krx = pd.read_html(url, header=0)[0]\n",
    "        krx = krx[['종목코드', '회사명']]\n",
    "        krx = krx.rename(columns={'종목코드': 'code', '회사명': 'company'})\n",
    "        krx.code = krx.code.map('{:06d}'.format)\n",
    "        return krx\n",
    "    def update_comp_info(self):\n",
    "        \"\"\"종목코드를 company_info 테이블에 업데이트 한 후 딕셔너리에 저장\"\"\"\n",
    "        sql = \"SELECT * FROM company_info\"\n",
    "        df = pd.read_sql(sql, self.conn)\n",
    "        for idx in range(len(df)):\n",
    "            self.codes[df['code'].values[idx]] = df['company'].values[idx]\n",
    "        with self.conn.cursor() as curs:\n",
    "            sql = \"SELECT max(last_update) FROM company_info\"\n",
    "            curs.execute(sql)\n",
    "            rs = curs.fetchone() # DB에서 가장 최근 업데이트 날짜를 가져옴\n",
    "            today = datetime.today().strftime('%Y-%m-%d')\n",
    "            if rs[0] == None or rs[0].strftime('%Y-%m-%d') < today: # rs에서 구한 날짜가 존재하지 않거나 오늘보다 오래된 경우에만 업데이트\n",
    "                krx = self.read_krx_code() # KRX 상장기업 목록 파일을 열서어 krx데이터프레임에 저장\n",
    "                for idx in range(len(krx)):\n",
    "                    code = krx.code.values[idx]\n",
    "                    company = krx.company.values[idx]                \n",
    "                    sql = f\"REPLACE INTO company_info (code, company, last\"\\\n",
    "                        f\"_update) VALUES ('{code}', '{company}', '{today}')\"\n",
    "                    curs.execute(sql)\n",
    "                    self.codes[code] = company\n",
    "                    tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "                    print(f\"[{tmnow}] #{idx+1:04d} REPLACE INTO company_info \"\\\n",
    "                        f\"VALUES ({code}, {company}, {today})\")\n",
    "                self.conn.commit()\n",
    "                print('')              \n",
    "    def read_naver(self, code, company, pages_to_fetch): \n",
    "        \"\"\"네이버에서 주식 시세를 읽어서 데이터프레임으로 반환\"\"\"\n",
    "        # try:\n",
    "        #     url = f\"http://finance.naver.com/item/sise_day.nhn?code={code}\"\n",
    "        #     with urlopen(url) as doc:\n",
    "        #         if doc is None:\n",
    "        #             return None\n",
    "        #         html = BeautifulSoup(doc, \"lxml\")\n",
    "        #         pgrr = html.find(\"td\", class_=\"pgRR\")\n",
    "        #         if pgrr is None:\n",
    "        #             return None\n",
    "        #         s = str(pgrr.a[\"href\"]).split('=')\n",
    "        #         lastpage = s[-1] \n",
    "        #     df = pd.DataFrame()\n",
    "        #     pages = min(int(lastpage), pages_to_fetch)\n",
    "        #     for page in range(1, pages + 1):\n",
    "        #         pg_url = '{}&page={}'.format(url, page)\n",
    "        #         df = df.append(pd.read_html(pg_url, header=0)[0])\n",
    "        #         tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        #         print('[{}] {} ({}) : {:04d}/{:04d} pages are downloading...'.\n",
    "        #             format(tmnow, company, code, page, pages), end=\"\\r\")\n",
    "        #     df = df.rename(columns={'날짜':'date','종가':'close','전일비':'diff'\n",
    "        #         ,'시가':'open','고가':'high','저가':'low','거래량':'volume'})\n",
    "        #     df['date'] = df['date'].replace('.', '-')\n",
    "        #     df = df.dropna()\n",
    "        #     df[['close', 'diff', 'open', 'high', 'low', 'volume']] = df[['close',\n",
    "        #         'diff', 'open', 'high', 'low', 'volume']].astype(int)\n",
    "        #     df = df[['date', 'open', 'high', 'low', 'close', 'diff', 'volume']]\n",
    "        try:\n",
    "            headers=('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36') \n",
    "            url = f'https://finance.naver.com/item/sise_day.nhn?code={code}' \n",
    "            opener = req.build_opener()\n",
    "            opener.addheaders = [headers]\n",
    "            response=opener.open(url)\n",
    "            doc=bs(response,'lxml')\n",
    "            last_page = doc.find('td',class_='pgRR').a['href'].split('=')[-1]\n",
    "            df=pd.DataFrame()\n",
    "            pages = min(int(last_page), pages_to_fetch)\n",
    "            for page in range(1, pages+1): # int(last_page)+1\n",
    "                page_url='{}&page={}'.format(url,page)\n",
    "                response=opener.open(page_url)\n",
    "                df=df.append(pd.read_html(response,header=0)[0])\n",
    "                tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "                print('[{}] {} ({}) : {:04d}/{:04d} pages are downloading...'.\n",
    "                    format(tmnow, company, code, page, pages), end=\"\\r\")\n",
    "            df = df.rename(columns={'날짜':'date','종가':'close','전일비':'diff'\n",
    "                ,'시가':'open','고가':'high','저가':'low','거래량':'volume'})\n",
    "            df['date'] = df['date'].replace('.', '-')\n",
    "            df = df.dropna()\n",
    "            df[['close', 'diff', 'open', 'high', 'low', 'volume']] = df[['close',\n",
    "                'diff', 'open', 'high', 'low', 'volume']].astype(int)\n",
    "            df = df[['date', 'open', 'high', 'low', 'close', 'diff', 'volume']]\n",
    "        except Exception as e:\n",
    "            print('Exception occured :', str(e))\n",
    "            return None\n",
    "        return df\n",
    "    def replace_into_db(self, df, num, code, company):\n",
    "        \"\"\"네이버에서 읽어온 주식 시세를 DB에 REPLACE\"\"\"\n",
    "        with self.conn.cursor() as curs:\n",
    "            for r in df.itertuples():\n",
    "                sql = f\"REPLACE INTO daily_price VALUES ('{code}', \"\\\n",
    "                    f\"'{r.date}', {r.open}, {r.high}, {r.low}, {r.close}, \"\\\n",
    "                    f\"{r.diff}, {r.volume})\"\n",
    "                curs.execute(sql)\n",
    "            self.conn.commit() # 마리아디비에 반영\n",
    "            print('[{}] #{:04d} {} ({}) : {} rows > REPLACE INTO daily_'\\\n",
    "                'price [OK]'.format(datetime.now().strftime('%Y-%m-%d'\\\n",
    "                ' %H:%M'), num+1, company, code, len(df)))\n",
    "    def update_daily_price(self, pages_to_fetch):\n",
    "        \"\"\"KRX 상장법인의 주식 시세를 네이버로부터 읽어서 DB에 업데이트\"\"\"  \n",
    "        for idx, code in enumerate(self.codes):\n",
    "            df = self.read_naver(code, self.codes[code], pages_to_fetch)\n",
    "            if df is None:\n",
    "                continue\n",
    "            self.replace_into_db(df, idx, code, self.codes[code])            \n",
    "    # json을 이용한 업데이트 페이지 수 설정\n",
    "    def execute_daily(self):\n",
    "        \"\"\"실행 즉시 및 매일 오후 다섯시에 daily_price 테이블 업데이트\"\"\"\n",
    "        self.update_comp_info() \n",
    "        try:\n",
    "            with open('config.json', 'r') as in_file:\n",
    "                config = json.load(in_file)\n",
    "                pages_to_fetch = config['pages_to_fetch'] # pages_to_fetch : 가져올 페이지 장 수(1페이지씩)\n",
    "        except FileNotFoundError:\n",
    "            with open('config.json', 'w') as out_file:\n",
    "                pages_to_fetch = 100 # 파일이 없으면 최초 실행시 100, 이후엔 1페이지씩 읽어옴\n",
    "                config = {'pages_to_fetch': 1}\n",
    "                json.dump(config, out_file)\n",
    "        self.update_daily_price(pages_to_fetch)\n",
    "        tmnow = datetime.now()\n",
    "        lastday = calendar.monthrange(tmnow.year, tmnow.month)[1]\n",
    "        if tmnow.month == 12 and tmnow.day == lastday:\n",
    "            tmnext = tmnow.replace(year=tmnow.year+1, month=1, day=1,\n",
    "                hour=17, minute=0, second=0)\n",
    "        elif tmnow.day == lastday:\n",
    "            tmnext = tmnow.replace(month=tmnow.month+1, day=1, hour=17,\n",
    "                minute=0, second=0)\n",
    "        else:\n",
    "            tmnext = tmnow.replace(day=tmnow.day+1, hour=17, minute=0,\n",
    "                second=0)   \n",
    "        tmdiff = tmnext - tmnow\n",
    "        secs = tmdiff.seconds\n",
    "        t = Timer(secs, self.execute_daily)\n",
    "        print(\"Waiting for next update ({}) ... \".format(tmnext.strftime\n",
    "            ('%Y-%m-%d %H:%M')))\n",
    "        t.start()\n",
    "if __name__ == '__main__':\n",
    "    dbu = DBUpdater()\n",
    "    dbu.execute_daily()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
