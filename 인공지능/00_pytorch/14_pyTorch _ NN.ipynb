{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"14_pyTorch : NN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOOKz23/7E//s/omUR0WTE7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNs3FQG67X18","executionInfo":{"status":"ok","timestamp":1621736326804,"user_tz":-540,"elapsed":3111,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"b3d0e2b1-0805-425a-9eb6-bb58f1871ad9"},"source":["import torch\n","import math\n","\n","x = torch.linspace(-math.pi, math.pi, 10)\n","y = torch.sin(x)\n","\n","p = torch.tensor([1, 2, 3])\n","xx = x.unsqueeze(-1).pow(p)\n","\n","# Sequential은 Module들을 순차적으로 적용하여, 출력을 생성함.\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(3, 1),\n","    torch.nn.Flatten(0, 1)\n",")\n","\n","# 손실 함수 정의\n","loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n","\n","lr = 1e-6\n","\n","for t in range(10000):\n","    #순전파\n","    y_pred = model(xx)\n","    loss = loss_fn(y_pred, y)\n","    if t % 1000 == 0:\n","        print(\"y_pred : {}\".format(y_pred))\n","        print(\"loss : {}\\n\".format(loss))\n","\n","\n","    model.zero_grad()\n","\n","    # 역전파\n","    loss.backward()    \n","    with torch.no_grad():\n","        for param in model.parameters():\n","            param -= lr * param.grad\n","linear_layer = model[0]\n","print(model[1])\n","print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"],"execution_count":39,"outputs":[{"output_type":"stream","text":["y_pred : tensor([-16.9342,  -8.3005,  -3.3953,  -1.1165,  -0.3623,  -0.0308,   0.9798,\n","          3.7717,   9.4465,  19.1063], grad_fn=<ViewBackward>)\n","loss : 801.7576293945312\n","\n","y_pred : tensor([ 0.2973, -0.1945, -0.4298, -0.4574, -0.3265, -0.0861,  0.2149,  0.5275,\n","         0.8026,  0.9913], grad_fn=<ViewBackward>)\n","loss : 2.5891425609588623\n","\n","y_pred : tensor([ 0.1863, -0.2853, -0.4897, -0.4859, -0.3327, -0.0891,  0.1859,  0.4333,\n","         0.5943,  0.6098], grad_fn=<ViewBackward>)\n","loss : 1.879004955291748\n","\n","y_pred : tensor([ 0.0530, -0.3718, -0.5381, -0.5061, -0.3363, -0.0890,  0.1755,  0.3968,\n","         0.5145,  0.4683], grad_fn=<ViewBackward>)\n","loss : 1.6493613719940186\n","\n","y_pred : tensor([-0.0207, -0.4218, -0.5673, -0.5189, -0.3383, -0.0872,  0.1726,  0.3797,\n","         0.4722,  0.3884], grad_fn=<ViewBackward>)\n","loss : 1.5553339719772339\n","\n","y_pred : tensor([-0.0608, -0.4511, -0.5856, -0.5274, -0.3394, -0.0847,  0.1739,  0.3732,\n","         0.4503,  0.3423], grad_fn=<ViewBackward>)\n","loss : 1.5038416385650635\n","\n","y_pred : tensor([-0.0821, -0.4689, -0.5980, -0.5336, -0.3401, -0.0817,  0.1773,  0.3726,\n","         0.4399,  0.3150], grad_fn=<ViewBackward>)\n","loss : 1.466034173965454\n","\n","y_pred : tensor([-0.0930, -0.4803, -0.6069, -0.5384, -0.3404, -0.0784,  0.1820,  0.3753,\n","         0.4359,  0.2982], grad_fn=<ViewBackward>)\n","loss : 1.4329614639282227\n","\n","y_pred : tensor([-0.0981, -0.4881, -0.6140, -0.5425, -0.3406, -0.0750,  0.1874,  0.3798,\n","         0.4353,  0.2872], grad_fn=<ViewBackward>)\n","loss : 1.4018383026123047\n","\n","y_pred : tensor([-0.1000, -0.4939, -0.6199, -0.5462, -0.3407, -0.0716,  0.1930,  0.3852,\n","         0.4367,  0.2795], grad_fn=<ViewBackward>)\n","loss : 1.3717888593673706\n","\n","Flatten(start_dim=0, end_dim=1)\n","Result: y = -0.20808199048042297 + 0.3945671319961548 x + 0.029873086139559746 x^2 + -0.0339493528008461 x^3\n"],"name":"stdout"}]}]}