{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_Transform.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZc8PqRddN2izp0kj/x4YW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DPVV_VmZo14f","executionInfo":{"status":"ok","timestamp":1621412030040,"user_tz":-540,"elapsed":879,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}}},"source":["# transforms은 전처리 관련 객체다.\n","\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","ds = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n","    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",")\n","\n","target_transform = Lambda(lambda y: torch.zeros(\n","    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RS4sZ92qch_"},"source":[""],"execution_count":null,"outputs":[]}]}