{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11_순역전파직접_pyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNnXkELsqKHvDGyplBfeyVN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vssa_myLsoqB","executionInfo":{"status":"ok","timestamp":1623054489213,"user_tz":-540,"elapsed":380,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"be1e8fad-072d-4b5a-b399-dbba541a547a"},"source":["import torch\n","import math\n","\n","dtype = torch.float\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","x = torch.linspace(1, math.pi, 3, device=device, dtype=dtype)\n","y = torch.sin(x)\n","print(\"y : {}\".format(y))\n","a = torch.randn((), device=device, dtype=dtype)\n","b = torch.randn((), device=device, dtype=dtype)\n","c = torch.randn((), device=device, dtype=dtype)\n","d = torch.randn((), device=device, dtype=dtype)\n","print(\"{} {} {} {}\".format(a,b,c,d))\n","lr = 0.0006\n","\n","# x를 가지고 y값을 예측.\n","for t in range(10000):\n","    # - 순전파 단계\n","    y_pred = a + b*x + c*x**2 + d*x**3 # 3차식으로 y값을 예측\n","    loss = (y_pred-y).pow(2).sum().item() # 모든 요소에 대해서, 오차 제곱의 합을 구함\n","    if t % 1000 == 0:\n","        print(\"y_pred : {}    loss : {}\".format(y_pred, loss))\n","    \n","    # - 역전파 단계\n","    # 오차와 x의 차수들로 변화율을 구한 다음, 학습률과 곱하여, 각 가중치들을, 갱신한다.\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_a = grad_y_pred.sum()\n","    grad_b = (grad_y_pred * x).sum()\n","    grad_c = (grad_y_pred * x ** 2).sum()\n","    grad_d = (grad_y_pred * x ** 3).sum()\n","    if t % 1000 == 0:\n","        print(\"grad_y_pred : \", grad_y_pred)\n","        print(\"grad_a : \", grad_a)\n","        print(\"grad_b : \", grad_b)\n","        print(\"grad_c : \", grad_c)\n","        print(\"grad_d : \", grad_d)\n","        print()\n","    a -= grad_a * lr\n","    b -= grad_b * lr\n","    c -= grad_c * lr\n","    d -= grad_d * lr\n","print(\"{} {} {} {}\".format(a,b,c,d))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["y : tensor([ 8.4147e-01,  8.7758e-01, -8.7423e-08], device='cuda:0')\n","0.0026981367263942957 0.7142823934555054 0.7385696172714233 0.6624144911766052\n","y_pred : tensor([ 2.1180, 10.5312, 30.0751], device='cuda:0')    loss : 999.3323364257812\n","grad_y_pred :  tensor([ 2.5530, 19.3072, 60.1502], device='cuda:0')\n","grad_a :  tensor(82.0104, device='cuda:0')\n","grad_b :  tensor(231.5017, device='cuda:0')\n","grad_c :  tensor(679.0046, device='cuda:0')\n","grad_d :  tensor(2039.0337, device='cuda:0')\n","\n","y_pred : tensor([ 0.6633,  1.0102, -0.0328], device='cuda:0')    loss : 0.05040588229894638\n","grad_y_pred :  tensor([-0.3563,  0.2653, -0.0657], device='cuda:0')\n","grad_a :  tensor(-0.1567, device='cuda:0')\n","grad_b :  tensor(-0.0133, device='cuda:0')\n","grad_c :  tensor(0.1332, device='cuda:0')\n","grad_d :  tensor(-0.0366, device='cuda:0')\n","\n","y_pred : tensor([ 0.7039,  0.9794, -0.0252], device='cuda:0')    loss : 0.02992589771747589\n","grad_y_pred :  tensor([-0.2752,  0.2036, -0.0503], device='cuda:0')\n","grad_a :  tensor(-0.1219, device='cuda:0')\n","grad_b :  tensor(-0.0117, device='cuda:0')\n","grad_c :  tensor(0.1012, device='cuda:0')\n","grad_d :  tensor(-0.0275, device='cuda:0')\n","\n","y_pred : tensor([ 0.7355,  0.9560, -0.0194], device='cuda:0')    loss : 0.01776704378426075\n","grad_y_pred :  tensor([-0.2120,  0.1569, -0.0388], device='cuda:0')\n","grad_a :  tensor(-0.0939, device='cuda:0')\n","grad_b :  tensor(-0.0090, device='cuda:0')\n","grad_c :  tensor(0.0780, device='cuda:0')\n","grad_d :  tensor(-0.0212, device='cuda:0')\n","\n","y_pred : tensor([ 0.7598,  0.9380, -0.0149], device='cuda:0')    loss : 0.010548356920480728\n","grad_y_pred :  tensor([-0.1634,  0.1209, -0.0299], device='cuda:0')\n","grad_a :  tensor(-0.0724, device='cuda:0')\n","grad_b :  tensor(-0.0069, device='cuda:0')\n","grad_c :  tensor(0.0601, device='cuda:0')\n","grad_d :  tensor(-0.0163, device='cuda:0')\n","\n","y_pred : tensor([ 0.7785,  0.9242, -0.0115], device='cuda:0')    loss : 0.0062626120634377\n","grad_y_pred :  tensor([-0.1259,  0.0931, -0.0230], device='cuda:0')\n","grad_a :  tensor(-0.0558, device='cuda:0')\n","grad_b :  tensor(-0.0053, device='cuda:0')\n","grad_c :  tensor(0.0463, device='cuda:0')\n","grad_d :  tensor(-0.0126, device='cuda:0')\n","\n","y_pred : tensor([ 0.7930,  0.9135, -0.0089], device='cuda:0')    loss : 0.0037181454245001078\n","grad_y_pred :  tensor([-0.0970,  0.0718, -0.0177], device='cuda:0')\n","grad_a :  tensor(-0.0430, device='cuda:0')\n","grad_b :  tensor(-0.0041, device='cuda:0')\n","grad_c :  tensor(0.0357, device='cuda:0')\n","grad_d :  tensor(-0.0097, device='cuda:0')\n","\n","y_pred : tensor([ 0.8041,  0.9052, -0.0068], device='cuda:0')    loss : 0.0022074657026678324\n","grad_y_pred :  tensor([-0.0747,  0.0553, -0.0137], device='cuda:0')\n","grad_a :  tensor(-0.0331, device='cuda:0')\n","grad_b :  tensor(-0.0032, device='cuda:0')\n","grad_c :  tensor(0.0275, device='cuda:0')\n","grad_d :  tensor(-0.0075, device='cuda:0')\n","\n","y_pred : tensor([ 0.8127,  0.8989, -0.0053], device='cuda:0')    loss : 0.0013105873949825764\n","grad_y_pred :  tensor([-0.0576,  0.0426, -0.0105], device='cuda:0')\n","grad_a :  tensor(-0.0255, device='cuda:0')\n","grad_b :  tensor(-0.0024, device='cuda:0')\n","grad_c :  tensor(0.0212, device='cuda:0')\n","grad_d :  tensor(-0.0058, device='cuda:0')\n","\n","y_pred : tensor([ 0.8193,  0.8940, -0.0041], device='cuda:0')    loss : 0.0007781079038977623\n","grad_y_pred :  tensor([-0.0444,  0.0328, -0.0081], device='cuda:0')\n","grad_a :  tensor(-0.0197, device='cuda:0')\n","grad_b :  tensor(-0.0019, device='cuda:0')\n","grad_c :  tensor(0.0163, device='cuda:0')\n","grad_d :  tensor(-0.0044, device='cuda:0')\n","\n","0.33043164014816284 0.5647135972976685 -0.004097340628504753 -0.0666709765791893\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZ9M-6k71lOT","executionInfo":{"status":"ok","timestamp":1621582450474,"user_tz":-540,"elapsed":321,"user":{"displayName":"우빈유","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giruu7KDv6pZHLhroAB5ik1oR9GCkEmJMtif6D4JQ=s64","userId":"08990466876548183706"}},"outputId":"736c539c-3452-4cbb-ab10-a066cbd4d6e0"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(27)"]},"metadata":{"tags":[]},"execution_count":16}]}]}